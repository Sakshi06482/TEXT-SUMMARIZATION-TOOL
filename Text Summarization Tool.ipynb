import nltk
nltk.download('stopwords', quiet=True)
from nltk.corpus import stopwords
Stop_words = set(stopwords.words('english'))
import heapq
import re
from nltk.tokenize import word_tokenize, sent_tokenize
def summarize_text(text, max_sentences = 3):
    # Text cleaning
    text = re.sub(r'\s+', '', text)
    text = re.sub(r'\[[0-9]*\]', ' ', text)

    # Tokenizing sentences and words
    sentences = sent_tokenize(text)
    Stop_words = set(stopwords.words('english'))

    word_frequencies = {}
    for word in word_tokenize(text.lower()):
        if word.isalpha() and word not in Stop_words:
            if word not in word_frequencies:
                word_frequencies[word] = 1
            else:
                word_frequencies[word] += 1

    #Normalizing frequencies
    max_frequency = max(word_frequencies.values(), default = 1)
    for word in word_frequencies.keys():
        word_frequencies[word] = (word_frequencies[word] / max_frequency)
        
    #Scoring sentences
    sentence_scores = {}
    for sentence in sentences:
        for word in word_tokenize(sentence.lower()):
            if word in word_frequencies:
                if len(sentence.split(' ')) < 30:
                     sentence_scores[sentence] = sentence_scores.get(sentence, 0) + word_frequencies[word]
    
    #Get top N sentences
    summary_sentences = heapq.nlargest(max_sentences, sentence_scores, key=sentence_scores.get)
    summary = ' '.join(summary_sentences).replace('\n', ' ').strip()
    return summary
# === Example Input ===
input_text = """
Artificial Intelligence (AI) is the simulation of human intelligence by machines, especially computer systems. It enables machines to learn from experience, adapt to new inputs, and perform tasks that typically require human intelligence. AI technologies include machine learning, natural language processing, robotics, and computer vision.

AI has evolved from simple rule-based systems to complex neural networks that mimic human brain activity. The widespread availability of big data, increased computing power, and advanced algorithms has accelerated AI development across various sectors.

One major application of AI is in healthcare, where it helps in disease diagnosis, drug discovery, and personalized treatment. In business, AI automates tasks, enhances customer service, and improves decision-making. Education systems use AI to personalize learning, while transportation benefits from AI through autonomous vehicles and traffic optimization.

Despite its advantages, AI poses significant challenges. Ethical concerns, such as bias in algorithms, data privacy issues, and job displacement due to automation, need to be addressed. There is growing interest in developing responsible and transparent AI systems.

AI is shaping the future by making systems smarter, faster, and more efficient. However, human oversight, ethical design, and regulation will be crucial in ensuring AI serves society positively.

"""
# === Output ===
print("Original Text:")
print(input_text)
print("\nSummarized Text:")
print(summarize_text(input_text, max_sentences=3))
